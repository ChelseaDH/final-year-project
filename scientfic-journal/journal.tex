\documentclass[11pt,a4paper,british]{bhamarticle}
\usepackage[margin=6.7em,bottom=8em,footskip=4em]{geometry}
\usepackage[utf8]{inputenc}
\usepackage{multicol}
\usepackage{float}
\usepackage{babel}
\usepackage{csquotes}
\usepackage{isodate}
\usepackage{fancyvrb}

% chktex-file 36

\usepackage{tikz}
\usetikzlibrary{calc,arrows}

\usepackage{enumitem}
\renewcommand\labelitemi{--}
\setlist[itemize]{leftmargin=*}

\usepackage[
    backend=biber,
    sorting=none,
    citestyle=numeric-comp
]{biblatex}
\usepackage[hidelinks]{hyperref}
\addbibresource{references.bib}

\setcounter{secnumdepth}{4}
\makeatletter
\newcounter{subsubsubsection}[subsubsection]
\def\thesubsubsubsection{\thesubsubsection.\arabic{subsubsubsection}}
\newcommand\subsubsubsection{%
    \@startsection{subsubsubsection}{4}
        {\z@}{1.4\parskip}{0.2\parskip}
        {\normalfont\normalsize\bfseries}
}
\newcommand*\l@subsubsubsection{\@dottedtocline{3}{10.0em}{4.1em}}
\newcommand*{\subsubsubsectionmark}[1]{}
\makeatother

% Fix paragraph spacing and use of noindent
\usepackage[parfill]{parskip}
\usepackage[raggedright]{titlesec}
\setlength{\columnsep}{14pt}
\titlespacing{\section}{0pt}{1.4\parskip}{0.2\parskip}
\titlespacing{\subsection}{0pt}{1.4\parskip}{0.2\parskip}
\titlespacing{\subsubsection}{0pt}{1.4\parskip}{0.2\parskip}
\titlespacing{\subsubsubsection}{0pt}{1.4\parskip}{0.2\parskip}

\title{A TCP/IP networking stack implementation in userland}
\author{Joe Groocock}
\supervisor{Dr Ian Batten}
\department{Computer Science}
\degree{Computer Science MSci}
\gyear{2017}

\begin{document}
\pagenumbering{gobble}

\maketitle

\begin{abstract}
    % TODO: Write coherent abstract
\end{abstract}


\pagenumbering{arabic}
\begin{multicols}{2}

\section{Introduction}
Transmission Control Protocol is an essential component of the modern internet used every day on all class of devices. It is the primary component in ensuring data is delivered reliably, in order and error-checked from end-to-end. TCP is often referred to as TCP/IP as it is tightly coupled with the lower layer \textit{Internet Protocol} that provides addressing and packet routing across large networks, like the public internet.

Over the years, TCP has been adapted and upgraded with extensions and variations to make it run more efficiently and intelligently, with improvements such as complex \textit{congestion control} algorithms to prevent systems and routers from getting overwhelmed, \textit{window scaling} to allow fast communicating clients to buffer more than the baseline 64 Kilobyte limit and \textit{Nagle's Algorithm}~\cite{rfc896} responsible for queuing small payloads of data together before sending to reduce multiple successive small packets being dispatched, amongst a long list of others extensions, some of which are defunct or have been replaced.

Every connected operating system contains a TCP/IP implementation from it's vendor, however most are based on the original Berkely TCP implementation from BSD Unix~\cite{rfc793} and have been adapted to work more efficiently in modern workloads. TCP is a solid protocol that is backwards compatible by design so any devices, dating back to the early 1980s, should still be able to communicate with modern systems. TCP implementations in most devices are well-written and have the benefit of almost 40 years of experience and incremental improvements. For general-use computing such as web browsing and downloading files, these improvements are sufficient and have been optimised as such.

Implementations in every major operating system allow for interaction with TCP via an \textit{Application Programming Interface} or API, to communicate with the enclosed network stack, however none of them allow access to view or modify the lower-level inner workings of the protocol. There are some use-cases where being able to interact, preview and utilise TCP can be useful, especially in software development and academic projects where low-level protocol access would be beneficial.

\subsection{Aim}\label{sec:aim}
The primary aim of this project is to provide, as a \textit{user} software library, a callable, interactive TCP/IP stack that can be used standalone, as a system daemon, for use by multiple processes, or to be picked apart and analysed for educational purposes. The code will be provided in a modular way such that parts can be called as desired, or replaced with alternative implementations as to observe the difference between the two.

It should also be globally compatible as only standard Linux features will be used ensuring maximum device compatibility.

Multiple similar programs exist that provide many of the same features, but none that are drop-in replacements for the inbuilt kernel stack that can be run without configuration as a userland application without the need for recompilation of the calling process. This project's aim is to provide a very simple user experience, where the network stack can be invoked at runtime to replace the traditional system calls:

\begin{center}
    \texttt{\$ netstack curl -vv \url{github.com}}
\end{center}

\section{TCP Overview}
Modern TCP is a very complex protocol with many extensions and experimental variations. This overview mostly covers the essentials as defined by the original specification, RFC~793~\cite{rfc793}. Extensions or variations are very useful for improving performance and reliability but absolutely not required for a functioning TCP. % chktex 13

\subsection{Terminology}
\begin{itemize}
    \item \texttt{SYN}: Synchronise\\
        \textit{Set to establish a new connection}
    \item \texttt{FIN}: Finish\\
        \textit{Indicate closure of existing connection}
    \item \texttt{ACK}: Acknowledgement\\
        \textit{Confirming that data arrived successfully or a acknowledging a command}
    \item \texttt{RST}: Reset\\
        \textit{Sent in reply to an invalid connection}
    \item Bit field: \textit{Data where each individual bit represents a boolean value e.g. 0 or 1}
\end{itemize}

\subsection{TCP packet header}
A TCP packet, or segment, contains an initial header followed by the packet payload. The header can be a variable length but is always at least 20 bytes and at most 60 bytes so small payloads are an inefficient use of a segment as there is always a 20+ byte overhead, per packet.

Most of the information carried in the header is metadata for identifying the connection and the data within the packet. Many of the values such as Sequence Number, Window size etc correspond to the sender; each peer will have their own individual values. In order of appearance, the fields in the header are as follows:

\begin{itemize}
    \item \textbf{Source Port} \textit{2 bytes} Port from which this packets was dispatched.
    \item \textbf{Destination Port} \textit{2 bytes} Port number open to receive on the recipient device.
    \item \textbf{Sequence Number} \textit{4 bytes} Sequential count of the first byte in the payload, identifying the sequence position of the segment.
    \item \textbf{Acknowledgement number} \textit{4 bytes} Sequential count of successfully received bytes.
    \item \textbf{Data offset} \textit{4 bits} Size of the TCP header in 32-bit words, as the header is padded to multiples of 4 bytes. This indicates the start of the payload and the end of the header within the packet.
    \item \textbf{Flags} \textit{12 bits} A \textit{bit field} containing the following control flags: \texttt{FIN}, \texttt{SYN}, \texttt{RST}, \texttt{PSH}, \texttt{ACK} and \texttt{URG}.
    \item \textbf{Window} \textit{2 bytes} Size, in bytes, of the receive window available to fill.
    \item \textbf{Checksum} \textit{2 bytes} The \textit{internet checksum}~\cite{internetchecksum} of the entire TCP segment and the upper \textit{Internet Protocol} layer. Used to ensure (probable) integrity of the data from corruption.
    \item \textbf{Urgent Pointer} \textit{2 bytes} Indicates the offset from the \textit{Sequence number} of the last urgent byte when the \texttt{URG} flag is set.
    \item \textbf{Options} \textit{0-40 bytes} Optionally, a series of TCP extension options followed by padding to the nearest 4th byte.% chktex 8
\end{itemize}

%   0                   1                   2                   3
%  0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1
% +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
% |          Source Port          |       Destination Port        |
% +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
% |                        Sequence Number                        |
% +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
% |                    Acknowledgement Number                     |
% +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
% |  Data |           |U|A|P|R|S|F|                               |
% | Offset| Reserved  |R|C|S|S|Y|I|            Window             |
% |       |           |G|K|H|T|N|N|                               |
% +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
% |           Checksum            |         Urgent Pointer        |
% +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
% |                    Options                    |    Padding    |
% +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
% |                             data                              |
% +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+

\subsection{Connection oriented}
One of the defining features of TCP is the famous \textit{three-way handshake}~(Figure~\ref{fig:threeway}) that every connection begins and ends with.

\begin{figure}[H]
    \begin{tikzpicture}[>=latex]
        \footnotesize
        \coordinate (TL) at (1.2,3);
        \coordinate (BL) at (1.2,0);
        \coordinate (TR) at (3.4,3);
        \coordinate (BR) at (3.4,0);
        \coordinate (LA) at ($(TL)!.25!(BL)$);
        \coordinate (LB) at ($(TL)!.65!(BL)$);
        \coordinate (LC) at ($(TL)!.70!(BL)$);
        \coordinate (LD) at ($(TL)!.75!(BL)$);
        \coordinate (RA) at ($(TR)!.14!(BR)$);
        \coordinate (RB) at ($(TR)!.40!(BR)$);
        \coordinate (RC) at ($(TR)!.45!(BR)$);
        \coordinate (RD) at ($(TR)!.50!(BR)$);
        \coordinate (RE) at ($(TR)!.90!(BR)$);
        % Lines & labels
        \draw (TL) node[above]{\large Client};
        \draw (TR) node[above]{\large Server};
        \draw[thick] (TL)--(BL) (TR)--(BR);
        % LISTEN
        \draw (RA) node[right]{%
            \begin{tabular}{l}
                \verb$LISTEN$\\
                \textit{passive open}
            \end{tabular}
        };
        % \texttt{SYN}
        \draw (LA) node[left]{%
            \begin{tabular}{r}
                \textit{active open}\\
                \verb$SYN_SENT$
            \end{tabular}
        };
        \draw[->] (LA) -- (RB) node[midway,sloped,above]{\verb$SYN$};
        \draw (RC) node[right]{%
            \begin{tabular}{l}
                \verb$SYN_RCVD$\
            \end{tabular}
        };
        % \texttt{SYN}/\texttt{ACK}
        \draw[->] (RD) -- (LB) node[midway,sloped,above]{\verb$SYN, ACK$};
        \draw (LC) node[left]{%
            \begin{tabular}{r}
                \verb$ESTABLISHED$\
            \end{tabular}
        };
        % \texttt{ACK}
        \draw[->] (LD) -- (RE) node[midway,sloped,above]{\verb$ACK$};
        \draw (RE) node[right]{%
            \begin{tabular}{l}
                \verb$ESTABLISHED$\
            \end{tabular}
        };
    \end{tikzpicture}
    \caption{Three-way handshake}\label{fig:threeway}
\end{figure}

A client requests a new connection by sending an initial packet with the \texttt{SYN} bit set, as well as an initial random \textit{Sequence number}. When a packet marked with \texttt{SYN} is received at the server, a new connection is being established and the server replies with a \texttt{SYN}/\texttt{ACK} packet. This reply does one of two things:
\begin{enumerate}
    \item The mutual \texttt{SYN} flag indicates the connection is being accepted along with a separate random sequence number.
    \item The \texttt{ACK} flag being set along with the \textit{Acknowledgement number} indicates it understood the initial \textit{Sequence number}.
\end{enumerate}
The sequence number from the initial flag is reused, incremented by one and sent back as the acknowledgement number in the \texttt{SYN}/\texttt{ACK} packet.

Finally, the client replies with the sequence number sent by the server, incremented by one, which completes the three-way handshake. At this point the connection is set up and ready to be used to transmit data.

When the connection is finished with, both endpoints need to mutually close the connection, in a very similar fashion to the \texttt{SYN}, \texttt{SYN}/\texttt{ACK}, \texttt{ACK} pattern.
Either side of the connection can initiate a \texttt{FIN} at any point, indicating there is no more data to send to which the peer must respond with an \texttt{ACK} of the final sequence number incremented by one to confirm the \texttt{FIN} packet was received.

Finish packets can behave slightly differently to \texttt{SYN} packets as there is no requirement to send a \texttt{FIN} packet immediately after receiving one. In fact, a connection can remain \textit{half closed} for quite a while whilst one side finishes transmitting data. This is a common pattern for some software applications as only simplex communication is required. It is also acceptable to close a connection quickly with \texttt{FIN}, \texttt{FIN}/\texttt{ACK}, \texttt{ACK}.

If at any point a \texttt{SYN}, \texttt{FIN} or other packet has not been acknowledged by the peer within a certain time frame, the packet will be resent under the assumption it never arrived; this is part of the reliability of TCP (See Section~\ref{sec:reliable}).

Following this pattern ensures both peers are in agreement of the state of the connection at all times. If at any point an invalid connection request is sent, to a closed port for example, it is instantly replied to with an \texttt{RST} packet indicating that the client should immediately discard of the connection as it is invalid.
\subsection{Ordered}
\textit{Sequence numbers} are used to track each individual byte sent over the connection. For each byte successfully received by the peer, the acknowledgement number is incremented to that value. Each packet contains a sequence number for the first byte of the payload in that segment indicating the position of the data in the continuous stream. If a packet arrives out of order, it can be kept aside until it is required or dropped and it will be retransmitted. Data that has been sent but not acknowledged is assumed to be lost so, after a timeout, it is retransmitted.

Quite often, especially with small local networks or across short distances, for the most part packets will arrive in order and complete so little retransmission is required, just some reordering and payload reassembly.

There are various methods of tracking missing packets, storing and reordering packets, indicating that packets are lost to reduce retransmission latency and so on that are used in TCP implementations which can improve performance and throughput in many cases, however, they are not required for basic TCP functionality.

\subsection{Reliable}\label{sec:reliable}
Acknowledging data is the first method used by TCP to ensure all data arrives intact. The sender keeps track of the sequence number of the lack acknowledgment it received and also keeps buffered the transmitted but unacknowledged data in the case where it has to be retransmitted. As data is received at the client, acknowledgements are sent in reply confirming the data was received.

Complementing that, a primitive checksum known as the \textit{Internet Checksum} is used to verify integrity of the data. By modern standards it is a very poor checksum implementation, however, it is very fast to compute and is still sufficient to ensure no serious corruption has occurred. In most cases, even if the checksum is still valid, corruption caused to the header could be detected and the packet will be discarded likely due to out-of-band sequence numbers or similar. The \textit{Internet Checksum} is defined as ``the 16 bit one's complement of the one's complement sum of all 16 bit words in the header and text''~\cite[3.1]{rfc793}.

\subsection{Extensible}
TCP has a vast array of extensions, specified in the `Option' section at the end of the packet header, that are used to fix many issues, improve performance and add extra functionality. This section will cover the commonly used options of note, but there are many more that are widely used and some still in development.

\subsubsection{Window Scaling}
At the advent of TCP, networks were comparatively slow of only a few Megabits per second, however, technology has advanced and now links are available in excess of 100 Gigabits per second. The default \textit{Window size} defined in TCP is only 64KiB which at 100Gbps can be filled in just 5 microseconds which can slow down transmission dramatically as the buffer has to be cleared before it can be filled again. To leverage these blistering transfer speeds, Window Scaling~\cite[2]{rfc1323} was introduced to increase the size of the default receive window. 

Window scaling must be negotiated during the initial handshake of the connection; a client requests wscale in the first \texttt{SYN} packet to which the peer replies with a wscale option in the returning \texttt{SYN}/\texttt{ACK} segment, confirming the choice to use scaling for the remainder of the connection. Should no reply to the wscale option be sent, it is assumed the peer does not support window scaling and therefore the connection must operate without scaling.

The option specifies a scale value between 0 and 14 which should be applied as a \textit{bitwise left shift} to the window size allowing a maximum receive window size of 1GiB ($65536 << 14$). It is completely valid to negotiate a `zero' shift in one direction to disable scaling for one client.

\subsubsection{Selective \texttt{ACK}}\label{sec:sack}
Acknowledgements are part of the reason TCP is so useful, but in particularly poor network conditions, the performance of TCP can suffer from excessive retransmissions, driving latency up and throughput down. Often in lossy transfers only a small amount of packets will be lost but TCP defines that data should be acknowledged until that point and all data afterwards will be retransmitted. It is often that most or all data after a missing packet will have arrived successfully but would be unnecessarily retransmitted.

Selective \texttt{ACK} aims to reduce and abolish retransmissions for data that has already arrived by indicating to the sender which blocks have or have not arrived. It is an option appended specifically to \texttt{ACK} packets to give more detail about which byte ranges should be retransmitted. The option has a variable payload length to allow inclusion of the left and right boundaries of each block that is being acknowledged.

\subsubsection{Nagle's Algorithm}
\citeauthor{rfc896} proposed in \citeyear{rfc896} the concept of reducing the amount of small packets being transmitted by buffering outgoing data for a small period of time before sending it. This is today known as \textit{Nagle's Algorithm} which is defined to address the ``small packet problem'' by not transmitting new data whilst there is still unacknowledged data in transmission. Sent data is queued indefinitely in the transmit buffer until an acknowledgment is received or until the buffer contains enough data to fill at least one segment.

The segment size in this case is the \textit{Maximum Segment Size} calculated by the lowest MTU in the route between the two communicating nodes, minus the header sizes. MSS tends to be 1460, or less, assuming the standard Ethernet (IEEE 802.3) MTU of 1500 is used.

\subsubsubsection{TCP Corking}
Linux implements a feature typically referred to as \texttt{TCP\_CORK} which is similar in nature to the operation of Nagle's Algorithm. The ultimate goal of corking is the same as Nagle, but is achieved in a different way. Corking will always buffer data, even after the reception of an acknowledgment, until there is enough to fill a segment or until the timeout has passed.  Linux uses a default corking timeout of 200ms.

\subsubsection{Congestion Control}
One of the final main features of TCP is the ability to survive and recover from network congestion with the use of complex control algorithms. Congestion control actually refers to a set of tools that a TCP should have, discussed in detail in the following sections:

\subsubsubsection{Slow Start}
A connection between two nodes is limited by the speed of the slowest intermediary node, such as a router, network interface or switch. To avoid overwhelming any of these devices resulting in packet loss, a TCP should assume the worst-case and start transmitting slowly. Congestion controlled TCP implementations maintain \textit{congestion window} which is the representation to the sender of the state of congestion in the network between the connected peers.

Slow start initialises a small congestion window, usually a small multiple of the MSS\@. Each time data is transmitted, the sender only releases at most the amount specified by the congestion window. For each acknowledgment received for all transmitted data, the congestion window is increased, often by a factor of two. Each subsequent transmission will be larger than the previous as the congestion window increases. When a lost segment is detected, slow start will stop and the standard linear growth Congestion Avoidance algorithm will kick in.

\subsubsubsection{Congestion Avoidance}
There have been many varying implementations of Congestion Avoidance algorithms with ranging feature sets for different scenarios. Some offer fast recovery, smaller loss or improved throughput. The aim of these algorithms is to continue a stable transmission between the two hosts whilst preventing subsequent packet loss by over-sending and overloading the network.

Popular algorithms for this are: Vegas, BIC, CUBIC, Westwood, Reno, Tahoe and New Reno. Typically `New Reno' is used in Unix systems today as it provides the best performance and stability with minimal changes required to either sender or receiver.


% TODO: Fix tenses (to past, mostly)
\section{Literature Review}
\subsection{\mbox{A brief look at related works}}
% RFC675 overview
When TCP was originally proposed in December 1974, by \citeauthor{rfc675} in RFC 675~\cite{rfc675}, flow diagrams and implementation suggestions were defined but lacked specific pseudo-code routines that could be implemented directly, were not provided. At that time TCP was young and naive due to having little exposure to real-world use cases. Furthermore, the limitations of the technology of the era were apparent in the original design given the scope and proposed use of the protocol, compared to the significantly higher speed demands in 2017.

% RFC793 overview & level-ip implementation to the spec
RFC 793 followed some years later and provided a more specific breakdown, that can be directly translated and implemented in code, of each event within the protocol and an appropriate procedure to handle it~\cite[Page~54-77]{rfc793}. \citeauthor{rfc793} who published the specification, now recognised as an official internet standard, defined TCP as `a connection-oriented, end-to-end reliable protocol' as it is now widely known. The document provides a well-defined list of requirements for the protocol to run, as well as a multitude of provisions for successful operation within the promises.
Many implementations of the TCP/IP stack including, but not limited to, `Level-IP' by \citeauthor{levelip-spec} follows this specification~\cite[\texttt{src/tcp\_input.c} line~262]{levelip-spec} very closely which, in theory, produces a TCP that should interwork seamlessly, as per the specification, with any other correctly implemented TCP. % chktex 13

% lwIP goals
Not all TCP/IP stacks are created equal; there are numerous incentives for developing alternate implementations, for example `lwIP' from \citeauthor{lwip}~(\citeyear{lwip}) was built `to reduce memory usage and code size, making lwIP suitable for use in small clients with very limited resources such as embedded systems'. There are many inefficiencies in `standard' networking stacks like those included in popular operating systems such as Linux, BSD, macOS and Windows, to name a few, especially regarding memory usage. These protocols make the assumption that the physical system has considerable amounts of memory available for receiving, processing and duplicating network data both in the kernel and in user applications.

\citeauthor{lwip} makes the opposite assumption and as a result produced a system where minimal replication of data and little wasted memory allocation occurs. Using dynamically sized packet buffers \texttt{pbufs}, \citeauthor{lwip} made efficient use of RAM, ROM and pooled memory to address network data without requiring it to be copied to a local storage space before being actioned. Through many small optimisations like these, lwIP was, and still is, a very effective network stack, usable on even the most restricted hardware which in the growing interconnected embedded device market is invaluable.
% TODO: Maybe talk about uIP here, if I have space/time/the will to live

% mTCP goals
Conversely, some alternate implementations exist for quite the opposite reasons such as `mTCP' \citeauthor{jeong2014mtcp}, which was constructed as `a highly scalable user-level TCP stack for multicore systems'. The intention was for mTCP to outperform competing solutions in packet throughput and data volume. According to their claims, mTCP can surpass Linux by a factor of 25 in `small message transactions' while also boosting regular performance of popular applications between 33\% and 320\%. Such performance numbers are impressive, especially considering the widespread use of Linux for commercial applications and hosting, which begs the question: ``Why is it significantly faster than the default Linux implementation and why hasn't Linux caught up yet?''~\cite[2.2, 3]{jeong2014mtcp}

Many of the improvements suggested by \citeauthor{jeong2014mtcp}~\cite{jeong2014mtcp} are very intelligent applications of high speed network adapters and multicore processor systems, such as servers. Any TCP network stack that is to be run in these kinds of scenarios should consider these optimisations for improved performance. It is likely that many of the proposed enhancements would also benefit low-power single CPU systems too, with the most probable outcome being reduced latency and memory usage.

\subsection{Demultiplexing TCP}\label{sec:demultiplex}
\citeauthor{braun:inria-00074040} designed a modified BSD TCP/IP stack where the IP layer resides in the kernel and TCP is split in two between kernel and userspace into TCPU and TCPK respectively. TCP processing is moved mostly into the user region, residing as local code in the calling process. The only exception to this is the `demultiplexing' step, TCPK, where TCP frames are routed to the correct user program based on the ports and addresses from the IP layer packet, providing security for the receiving process.

% Demultiplexing in userspace, or not
\citeauthor{braun:inria-00074040} theorised that a potential alternative method for demultiplexing packets would be to pass all incoming traffic directly into a userspace daemon for processing, removing the requirement on kernel modifications. However, it is concluded that this concept is impractical and inefficient compared with the alternative solution (above) as packets are processed by two userspace applications, causing more context switches passing data from the daemon to the receiving processes~\cite[2.1]{braun:inria-00074040}\cite[3]{edwards1995experiences}. Generally, this assumption of relative inefficiency is true, however, in certain circumstances there can be situations where this is actually a practical and viable solution. This project aims to implement a usermode-only networking stack, meaning kernel modifications are not plausible and therefore this solution is ideal when optimised appropriately, reducing the context switching overhead.

\subsection{Throughput performance}\label{sec:thruput}
Much of the research surrounding TCP, particularly that providing userspace implementation detail, is focussed on optimising the protocol for high performance and high throughput. \citeauthor{edwards1995experiences}, in \citeyear{edwards1995experiences} demonstrated throughput of 160 Mbit/s using a userspace TCP implementation running over coaxial token-ring ATM networking, making use of the solid existing HP-UX kernel TCP code along with single-copy from the NIC to the user application using shared memory in the TCP stack and the application. This particular arrangement managed 80\% of the performance of the existing single-copy TCP stack and 150\% of the double-copy kernel stack. \citeauthor{braun:inria-00074040} in \citeyear{braun:inria-00074040} yielded similar results of around 40-50\%~\cite[5]{braun:inria-00074040} between the default kernel and TCPU/TCPK stacks running on much less powerful hardware. % chktex 8
% TODO: Talk about lwIP here (2,6,12)
%     Copying from kernel <-> user

% mTCP thread-local storage and multicore
\citeauthor{jeong2014mtcp} shows that with the use of multiple receive queues spread across individual CPU cores and fewer locks along with improved buffer management and fewer context switches between kernel and user mode their implementation can yield a much improved throughput compared to Linux and other user-mode concepts. Much of the improved performance is thanks to the use of \textit{thread local storage} of socket buffers, TCP buffer pools and other data structures relating to individual threads that are not shared. Greatly reduced usage of locks across threads, reducing \textit{Lock contention}, helps to minimise idle time in both incoming and outgoing packet processing.

\subsection{Reducing data copying overhead}\label{sec:reducecopy}
A common theme across many protocol implementations is the focus on reducing overhead due to data copying. Any copied data is potential wasted time, especially if the same functionality could be programmed using a \textit{zero-copy} approach, where incoming packets are deposited directly from the network adapter into the user program without being duplicated one or more times. Many of the related works include some variation of a transmit/receive queue utilised by every layer from the NIC to the user program, minimal or zero data copying. \citeauthor{jeong2014mtcp} utilised an event-driven packet I/O library to divide incoming batches of packets into multiple queues written directly from the network interface and passed directly through into the user TCP~\cite[3.1]{jeong2014mtcp}.

\citeauthor{braun:inria-00074040} took a different approach to reducing data copying where typically packet buffers are copied twice: once from the device to an input buffer queue then secondly into the application buffer. In certain situations, by the process of \textit{header prediction}, the kernel copies the header data only. Then assuming the predicted header size was correct, enclosed packet data is copied directly into the user program receive buffer~\cite[4.1]{braun:inria-00074040}. By modern standards this is less than optimal, as now there exists suitable methods to skip copying entirely and use memory-mapped buffers.

Due to the limitations of the BSD socket API, \textit{zero-copy} networking is not trivially implemented without some significant changes to how data is copied into the user memory, although there is one solution that harnesses the power of hardware offload. Using a feature of virtual memory to remap memory pages, data can be offloaded by the network interface directly into aligned memory pages, separating header from the payload~\cite[2.3]{chase2001end}. Specific hardware and driver support is required for this, and even more complex connection tracking is required for TCP offload. A result of the memory page mapping is large contiguous blocks of memory containing packet payloads produced without a single data copy.

\subsection{TCP security considerations}
By moving processing from kernel to userspace, protections such as obscurity from other programs is reduced. \citeauthor{braun:inria-00074040} raised the issue that with a userspace TCP process, data for multiple connections is loaded into the memory space of a single process, enabling it to be viewed or modified by any privileged program~\cite[1, 2.1]{braun:inria-00074040}. In most cases this is not a significant issue, however, it should still be considered. The only plausible solution is to move the demultiplexing stage back into the kernel to restore the connection security.

% Comparison of kernel vs userspace
%   Problems with each
%       (lwIP 4)
%   Limitations of kernel
%     (mtcp 2.1)
%   Limitations of userspace
%     High-precision timers
%       (mtcp 3.2.2)
%       (RR-2650 4.2)
%       (lwIP 5)
%   Half-half implementations
%     (HP 4.4.8)
%     (RR-2650 1, 2)

\section{Implementation Detail}

% Produce a specification

% List 'user' requirements
\subsection{Requirements}
\begin{itemize}
    \item This project must produce a TCP/IP implementation that runs completely in Linux userspace with no/minimal kernel modification
    \item This project must follow the original RFC 793~\cite{rfc793} specification for TCP
    \item This project must provide a network stack as a library such that it can be easily implemented in other software
        \begin{itemize}
            \item There should be sufficient documentation to demonstrate examples of how this can be achieved
        \end{itemize}
    \item This project should provide sufficient interface to the user to view the inner workings of a TCP connection
    \item This project could implement modern TCP extensions such as Window Scaling, Selective \texttt{ACK} and Congestion Control.
\end{itemize}

Building a TCP/IP stack is a layered process, similarly to how network protocols are layered. To be able to process TCP, there should be a solid IP protocol to route packets. Before IP can be handled an ethernet layer is required so frames can be retrieved and decoded.

\subsection{Network communication}
The first stage of this implementation is to procure and decode ethernet frames that arrive at the network adapter. Linux provides several methods of reading and writing `raw' network packets to and from the wire:
\subsubsection{Raw Sockets}
\begin{Verbatim}[fontsize=\small]
socket(AF_INET, SOCK_RAW, IPPROTO_RAW);
\end{Verbatim}
Making use of the standard BSD \texttt{socket()} API, a raw socket provides IP packets complete with the header and with the link layer headers stripped, which is probably ethernet. Using \texttt{IPPROTO\_RAW} implies the use of \texttt{IP\_HDRINCL} which both provides the IP header for incoming packets and expects it for outgoing packets.

Alternatively the protocol could be specified as \texttt{IPPROTO\_IP} which would skip the header requirement. As part of the kernel IP stack is used, incoming IP packet fragments are pre-reassembled. This method is very convenient because it is portable, it should work on \textit{any} BSD-compatible Unix, not just Linux. Conveniently the routing is also provided with the default kernel routing tables, directing the packets out of the correct interface for the destination.

This approach does have the rather large caveat that \texttt{IPPROTO\_RAW} can only be used for sending data, not receiving, rendering it useless for this application.

\subsubsection{Packet sockets}
\begin{Verbatim}[fontsize=\small]
socket(AF_PACKET, SOCK_RAW, ETH_P_ALL);
\end{Verbatim}
Also using the BSD \texttt{socket()} API, this is a standard socket that produces entire ethernet frames captured before kernel processing. \texttt{AF\_PACKET} provides nice-to-have features such as (optionally) stripping the ethernet frame header with \texttt{SOCK\_DGRAM}.

Packet sockets have the limitation of suffering from the performance penalties discussed in Sections~\ref{sec:thruput} and~\ref{sec:reducecopy}. Packet sockets also require the Linux \textit{capability} of \texttt{CAP\_NET\_ADMIN} to open the socket, or effective root permission.

\subsubsection{Linux tpacket interface}
Linux provides an extension to the standard \texttt{AF\_PACKET} interface by means of \texttt{mmap()} and a \textit{circular ring buffer} known as tpacket~\cite{tpacket}, provided by the \texttt{PACKET\_MMAP} kernel option. \texttt{PACKET\_MMAP} provides ``a size configurable circular buffer mapping in user space that can be used to either send or receive packets''. The opened socket must be bound to a single network interface that can be monitored and probed for packet reception. Compared to a standard packet socket, ``\texttt{PACKET\_MMAP} is very efficient''; this solves one of the primary issues of implementing network protocols in userspace (see Section~\ref{sec:reducecopy}).

\subsubsection{TUN/TAP devices}
Standard virtual network adapters known as TUN and TAP adapters can also be used to interface software with a network; they are popular with Virtual Private Network applications such as OpenVPN that provide network functionality through software. TAP adapters provide layer 2 network access to ethernet frames and similar transport mediums. TUN devices operate on layer 3 so provide IP packets. These devices rely on the host networking stack so must be bridged (for TAP devices), or routed (for TUN devices) appropriately to allow communications to pass. Initial setup of these kinds of adapters can be more complex initially but can allow for varying configurations should the user require it. Similarly, these can be used to provide physical network access to the library or binaries

\subsubsection{libpcap}
A popular tool for low-level packet capture is libpcap which was written precisely for that purpose. It provides many ways of sending and receiving low-level packet data, similar to the \texttt{socket()} API but with a more straightforward abstraction. Internally libpcap uses tpacket, when it is available, otherwise falls back to slower methods. The abstraction provided by libpcap would benefit this project little as it does not avoid the issue of redundant data copying and would add an unwanted extra dependency to the library.

In practice there is no perfect solution to this problem. Some older or less powerful systems will not support the faster and more modern features like \texttt{PACKET\_MMAP} so a fallback solution like packet sockets or TUN/TAP devices can be used. This should also be a configurable option for the user of the software to suit their needs best as some approaches fit particular use-cases better than others. Most of these options will likely be implemented and available to use for flexibility at runtime.

\subsection{Demultiplexing packets}\label{sec:impl-demult}
`Demultiplexing' in the context of TCP packets is the process of delegating responsibility of processing to another place, based on a feature of the data. More specifically, it defines which process should handle a packet based on the TCP connection, and socket, it belongs to, determined by the IP addresses and ports in the packet. These 4 pieces of information together form the identifying `state' of a connection. Any packet containing the same 4 IP addresses and port number values belongs to the same connection.

Following the discussion in Section~\ref{sec:demultiplex}, it was concluded that demultiplexing incoming packets in the kernel was the faster and more efficient solution as it reduces the amount of context switches by at least half. Also as discussed previously, given the aim and restrictions of the project, implementing in kernel-space cannot happen so it will reside in userspace.

Resources wasted by userspace processes can often be caused by excessive \textit{context switching}, that is making \textit{system calls} into the kernel for example to read from a file, write to a socket or perform memory allocation operations. Context switches interrupt the normal process execution flow and schedule a switch to kernel mode for the syscall to be handled, before switching back. Each switch causes a small delay as the scheduler queues the events before they occur and the delays accumulate to a significant amount of time that could be otherwise used by the process to run computation.

Reducing context switches is one method of reducing wasted CPU time and improving performance. Batching together requests such as incoming packet transfers is one way of achieving this. Packets can be queued in the ring buffer until there are enough to warrant a context switch to retrieve them.

Another method for reducing context switches is to abolish them in favour of other communication methods such as sharing memory between processes. When transferring demultiplexed packets from the daemon process to the destination user process, the packet memory buffer can be mapped between the processes, giving them both access, and the only remaining context switch is to send a notification from one process to the other. This can be achieved through many methods:
\subsubsection{Process signals} 
POSIX defines a standard set of signals that can be sent between processes. A signal is an interrupt with a value associated with the intent of the destination process handling it. Signals are most commonly used to request or force termination of a process but can also be used for basic IPC\@. The function \texttt{kill(pid, signal)} is used for sending signals to a process. POSIX also defines a function \texttt{sigqueue(pid, signal, sigval)} which allows a single integer or pointer to the destination process.

Paired with shared memory, signals can be an effective method of inter-process communication: shared memory to pass information and signalling to notify the sibling process of a change. To prevent concurrency errors locks such as \textit{mutual exclusions} should probably be used to prevent race conditions etc.

\subsubsection{Unix pipes}
A standard feature provided by all Unix-compatible operating systems is so called `pipes' which are memory-mapped files that join two processes together. They behave very similarly to files or sockets where data is written into the pipe and read back out on the other side. A communication protocol can be established and used to communicate from one process to another. A drawback of this mechanism is that it is unidirectional. Two pipes would have to be opened for bidirectional communication. There is also the overhead of writing, buffering and reading the response, via the kernel.

\subsubsection{Unix domain sockets}
These behave very similarly to Unix pipes in that data is written in one side and read out of the other. They have the advantage of being bidirectional by default as they are more closely modelled on continuous-stream network protocols like TCP\@. They are also created in the same way as network sockets, except the family \texttt{AF\_UNIX} is specified instead of \texttt{AF\_INET} as would be used for an internet socket.

\subsubsection{Semaphores}
Most operating systems also define a signalling mechanism known as `Semaphores' which are an \textit{atomic} counter representing the state of a resource. Due to their inherent atomicity, they are very useful for providing signalling as well as locking to shared resources between processes. Semaphores can be used to convey intent to access a shared resource then lock it to prevent concurrency errors whilst it is locked. This approach also avoids unwanted context switches into the kernel to retrieve new data. Instead it is copied directly into the daemon process and also mapped into the destination process with communication to signal changes being direct between processes using the semaphore mechanism.

For the purpose of this project, semaphores most likely will provide the best performance and flexibility when paired with memory-mapped network packets using shared memory. This complex combination of features will prove difficult to implement and will likely cause some difficult to solve errors however together they solve the task best out of the available options.

%\subsection{TCP timers}
\subsection{Modes of Operation}
\subsubsection{Inclusion as a library}
Allowing the user flexibility with the network stack as a callable entity is the simplest situation as all that is required is a single library object with an API and sufficient usage documentation. It is the responsibility of the user application to call the networking initialisation routines, configure interfaces and perform optional inter-process communication if it is required. The network stack must be self-contained and thread-safe to prevent causing unwanted bugs in user programs.

\subsubsection{Running as a standalone program}
As only one process is involved in the lifecycle of this scenario, complex inter-process communication is not necessary and the demultiplexing stage of processing can be simplified and internalised.
This is the more common use-case for this project, providing a single network stack with one or more sockets in short-lived processes. For example, the given usage suggestion in Section~\ref{sec:aim} is representative of how a standalone tool might be used.

TCP connections will be processed within the process, directly alongside demultiplexing, all running in separate threads to the main process worker thread. Standard libc function calls such as \texttt{socket()}, \texttt{read()} and \texttt{write()} will have to be hijacked and redirected to the in-process stack instead of the standard operation of making system calls. This can be accomplished through a feature of the dynamic loader, `ld', that loads shared libraries into dynamic binaries at runtime. A hijacking library can be injected before the execution of the process starts to redirect the relevant function calls using `libdl' and initialise the internal network stack, before resuming the normal process entry point.

\subsubsection{Running as a system daemon}\label{sec:standalone}
Complexity in the form of required inter-process communication and distributed connection tracking is required for this scenario. A separate daemon process gives the freedom to run many sibling processes, with one or more open sockets each, all handled through the single `master' daemon. The requirement for this to work is solid communication channel between the master and slave processes using the discussed methods in Section~\ref{sec:impl-demult}.

Many of the execution routines for initialising the slave processes are similar to those in Section~\ref{sec:standalone}. The differences are that a connection will be attempted to the master daemon process to initialise and shutdown connections created by the \texttt{socket()} call. This construction should provide flexibility to run in one of two operating methods:
\begin{enumerate}
    \item{All TCP connections are handled by the master process}: \textit{Slave processes will call \texttt{read()} and \texttt{write()} to request data from the master process. Demultiplexing and TCP processing happen concurrently, for all TCP connections across all processes, in the single daemon process, and just payload data is exchanged with the destination process.}
    \item{TCP connections are handled by the individual destination processes} \textit{The daemon process is only responsible for exchange of network packets from the interface and demultiplexing packets before they are handed over to the client applications for TCP processing.}
\end{enumerate}

% Why do we use the Linux kernel's TCP stack?
% https://jvns.ca/blog/2016/06/30/why-do-we-use-the-linux-kernels-tcp-stack/
% https://github.com/lkl/linux
% https://news.ycombinator.com/item?id=12021195

% Features I would like:
%   - Multiple interfaces: tpacket, rawsock, rawinet, tun, tap
%     - Defaults to tpacket, whichever version is supported as it
%       is quickest, fallback to rawsock
%   - Running as a system daemon or a standalone hook-in
%     See also: https://github.com/lkl/linux/blob/master/tools/lkl/lib/hijack/hijack.c
%     - Standalone will use libdl to override libc calls
%       like socket(), recv() and listen() etc
%       - Limitations on file descriptor and port number clashes
%         - Use fds > FD_SETSIZE (1024)? Maybe ulimit will mess with us here
%     - System daemon will connect to other programs either
%       via compiled-in support through libnetstack or another
%       binary that uses libdl and hooks syscalls, like standalone
%   - Options:
%     See also: https://tools.ietf.org/html/rfc7414
%     - Window Scaling is a must. Performance relies on it
%     - SACK
%     - Timestamps?


\section{Implementation Issues}
\subsection{Hijacking the BSD \texttt{socket()} API calls} % chktex 36
% Allocating file descriptors such that they don't clash with standard kernel fds

\subsection{Frames larger than the interface MTU}
% Caused by 'segmentation offloading'
% Affects TCP checksums on packets greater than MSS/MTU

% Using iptables or libiptc to drop RST on specific ports
\subsection{Fighting the Linux TCP/IP stack \texttt{RST} packets}
%  - Port can't be used by the kernel and could clash?
%  - outside of /proc/sys/net/ipv4/ip_local_port_range
% Opening the socket to accept the connection
%  - Eventually socket will timeout
%  - Doesn't block any packets from actually getting out
% Kernel module/extension to prevent RST being generated
%  - Could be quicker but defeats isn't truly userspace

\subsection{Efficiently sending and receiving packets through the kernel interface}
\cite{tpacket} % chktex 2
% "it requires one system call to capture each packet, it requires two if you want to get packet's timestamp"
% Use a zero-copy interface like Linux tpacket_v{1,2,3}
%   BSD socket API doesn't allow for zero-copy as it has no notion of packet buffers and payload segmentation
% Communicating data between daemon and user process without copy (SHM?)

% Signal handling, such as SIGSTP breaking timing

\printbibliography % chktex 1
\end{multicols}
\end{document}
